{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1a: Classification with Decision Trees\n",
    "**DUE September 17th 2018**\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The code for this project consists of several Python files, some of\n",
    "which you will need to read and understand in order to complete the\n",
    "assignment, and some of which you can ignore.\n",
    "\n",
    "### Files You'll Edit\n",
    "\n",
    "``assignment_1b.ipynb``: Will be your edited copy of this notebook pertaining to part 1a of the assignment.\n",
    "\n",
    "`titanic-features.py`: This contains some functions to help you apply a decision tree to the Titanic dataset.\n",
    "\n",
    "\n",
    "### Files you might want to look at\n",
    "  \n",
    "``binary.py``: Our generic interface for binary classifiers (actually\n",
    "works for regression and other types of classification, too).\n",
    "\n",
    "``datasets.py``: Where a handful of test data sets are stored.\n",
    "\n",
    "``util.py``: A handful of useful utility functions: these will\n",
    "undoubtedly be helpful to you, so take a look!\n",
    "\n",
    "``runClassifier.py``: A few wrappers for doing useful things with\n",
    "classifiers, like training them, generating learning curves, etc.\n",
    "\n",
    "``mlGraphics.py``: A few useful plotting commands\n",
    "\n",
    "``data/*``: all of the datasets we'll use.\n",
    "\n",
    "### What to Submit\n",
    "\n",
    "You will hand in all of the python files listed above under \"Files\n",
    "you'll edit\". You will also have to answer the written questions in this\n",
    "notebook denoted **Q#:** in the corresponding cells denoted with **A#:**.\n",
    "\n",
    "#### Autograding\n",
    "\n",
    "Your code will be autograded for technical correctness. Please **do\n",
    "not** change the names of any provided functions or classes within the\n",
    "code, or you will wreak havoc on the autograder. However, the\n",
    "correctness of your implementation -- not the autograder's output --\n",
    "will be the final judge of your score.  If necessary, we will review\n",
    "and grade assignments individually to ensure that you receive due\n",
    "credit for your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter magic!\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Warming up to Classifiers (10%)\n",
    "\n",
    "Let's begin our foray into classification by looking at some very\n",
    "simple classifiers.  There are three classifiers\n",
    "in ``dumbClassifiers.py``, one is implemented for you, the other\n",
    "two you will need to fill in appropriately.\n",
    "\n",
    "The already implemented one is ``AlwaysPredictOne``, a classifier that\n",
    "(as its name suggest) always predicts the positive class.  We're going\n",
    "to use the ``TennisData`` dataset from ``datasets.py`` as a running\n",
    "example.  So let's start up python and see how well this classifier\n",
    "does on this data.  You should begin by importing ``util``,\n",
    "``datasets``, ``binary`` and ``dumbClassifiers``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dumbClassifiers, datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = dumbClassifiers.AlwaysPredictOne({})\n",
    "h.train(datasets.TennisData.X, datasets.TennisData.Y)\n",
    "h.predictAll(datasets.TennisData.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, it looks like it's always predicting one!\n",
    "\n",
    "Now, let's compare these predictions to the truth.  Here's a very\n",
    "clever way to compute accuracies \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((datasets.TennisData.Y > 0) == (h.predictAll(datasets.TennisData.X) > 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1:** Why is this computation equivalent to computing classification accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A1:** (TODO: Enter answer here...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's training accuracy; let's check test accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((datasets.TennisData.Yte > 0) == (h.predictAll(datasets.TennisData.Xte) > 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so it does pretty badly.  That's not surprising, it's really not\n",
    "learning anything!!!\n",
    "\n",
    "Now, let's use some of the built-in functionality to help do some of\n",
    "the grunt work for us.  We'll need to import ``runClassifier``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import runClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runClassifier.trainTestSet(h, datasets.TennisData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very convenient!\n",
    "\n",
    "Now, your first implementation task will be to implement the missing\n",
    "functionality in ``AlwaysPredictMostFrequent``.  This actually\n",
    "will \"learn\" something simple.  Upon receiving training data, it will\n",
    "simply remember whether +1 is more common or -1 is more common.  It\n",
    "will then always predict this label for future data.  **Once you've\n",
    "implemented this**, you can test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = dumbClassifiers.AlwaysPredictMostFrequent({})\n",
    "################################################################################\n",
    "# TODO: Implement AlwaysPredictMostFrequent                                    #\n",
    "################################################################################\n",
    "runClassifier.trainTestSet(h, datasets.TennisData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so it does the same as ``AlwaysPredictOne``, but that's\n",
    "because +1 is more common in that training data.  We can see a\n",
    "difference if we change to a different dataset: ``SentimentData`` is\n",
    "the data you've seen before, now Python-ified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runClassifier.trainTestSet(dumbClassifiers.AlwaysPredictOne({}), datasets.SentimentData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runClassifier.trainTestSet(dumbClassifiers.AlwaysPredictMostFrequent({}), datasets.SentimentData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last dumb classifier we'll implement\n",
    "is ``FirstFeatureClassifier``.  This actually does something\n",
    "slightly non-trivial.  It looks at the first feature\n",
    "(i.e., ``X[0]``) and uses this to make a prediction.  Based on\n",
    "the training data, it figures out what is the most common class for\n",
    "the case when ``X[0] > 0`` and the most common class for the case\n",
    "when ``X[0] <= 0``.  Upon receiving a test point, it checks the\n",
    "value of ``X[0]`` and returns the corresponding class.  **Once\n",
    "you've implemented this**, you can check it's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO: Implement FirstFeatureClassifier                                       #\n",
    "################################################################################\n",
    "runClassifier.trainTestSet(dumbClassifiers.FirstFeatureClassifier({}), datasets.TennisData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runClassifier.trainTestSet(dumbClassifiers.FirstFeatureClassifier({}), datasets.SentimentData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Decision Trees\n",
    "\n",
    "Our next task is to implement a decision tree classifier.  There is\n",
    "stub code in ``dt.py`` that you should edit.  Decision trees are\n",
    "stored as simple data structures.  Each node in the tree has\n",
    "a ``.isLeaf`` boolean that tells us if this node is a leaf (as\n",
    "opposed to an internal node).  Leaf nodes have a ``.label`` field\n",
    "that says what class to return at this leaf.  Internal nodes have:\n",
    "a ``.feature`` value that tells us what feature to split on;\n",
    "a ``.left`` *tree* that tells us what to do when the feature\n",
    "value is *less than 0.5*; and a ``.right`` *tree* that\n",
    "tells us what to do when the feature value is *at least 0.5*.\n",
    "To get a sense of how the data structure works, look at\n",
    "the ``displayTree`` function that prints out a tree.\n",
    "\n",
    "Your first task is to implement the training procedure for decision\n",
    "trees.  We've provided a fair amount of the code, which should help\n",
    "you guard against corner cases.  (Hint: take a look\n",
    "at ``util.py`` for some useful functions for implementing\n",
    "training.  **Once you've implemented the training function**, we can test\n",
    "it on simple data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = dt.DT({'maxDepth': 1})\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO: Implement dt.train(...)                                                #\n",
    "################################################################################\n",
    "h.train(datasets.TennisData.X, datasets.TennisData.Y)\n",
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is for a simple depth-one decision tree (aka a decision stump).\n",
    "If we let it get deeper, we get things like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = dt.DT({'maxDepth': 2})\n",
    "h.train(datasets.TennisData.X, datasets.TennisData.Y)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = dt.DT({'maxDepth': 5})\n",
    "h.train(datasets.TennisData.X, datasets.TennisData.Y)\n",
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do something similar on the sentiment data (this will take a bit longer---it takes about 10 seconds on my laptop):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = dt.DT({'maxDepth': 2})\n",
    "h.train(datasets.SentimentData.X, datasets.SentimentData.Y)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = dt.DT({'maxDepth': 2})\n",
    "h.train(datasets.SentimentData.X, datasets.SentimentData.Y)\n",
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem here is that words have been converted into numeric ids\n",
    "for features. We can look them up (your results here might be\n",
    "different due to hashing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(2428, datasets.SentimentData.words[2428])\n",
    "print(3842, datasets.SentimentData.words[3842])\n",
    "print(3892, datasets.SentimentData.words[3892])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this, we can rewrite the tree (by hand) as:\n",
    "\n",
    "```python\n",
    "Branch 'bad'\n",
    "  Branch 'worst'\n",
    "    Leaf -1.0\n",
    "    Leaf 1.0\n",
    "  Branch 'sequence'\n",
    "    Leaf -1.0\n",
    "    Leaf 1.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you should **go implement prediction**.  This should be easier than\n",
    "training!  We can test by (this takes about a minute for me):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO: Implement dt.predict(...)                                              #\n",
    "################################################################################\n",
    "runClassifier.trainTestSet(dt.DT({'maxDepth': 1}), datasets.SentimentData)\n",
    "runClassifier.trainTestSet(dt.DT({'maxDepth': 3}), datasets.SentimentData)\n",
    "runClassifier.trainTestSet(dt.DT({'maxDepth': 5}), datasets.SentimentData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it does better than the dumb classifiers on training data,\n",
    "as well as on test data!  Hopefully we can do even better in the\n",
    "future!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use more ``runClassifier`` functions to generate learning\n",
    "curves and hyperparameter curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve = runClassifier.learningCurveSet(dt.DT({'maxDepth': 9}), datasets.SentimentData)\n",
    "runClassifier.plotCurve('DT on Sentiment Data', curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plots training and test accuracy as a function of the number of\n",
    "data points (x-axis) used for training and y-axis is accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2:** We should see training accuracy (roughly) going down and test\n",
    "accuracy (roughly) going up.  Why does training accuracy tend to go\n",
    "*down?* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A2:** (TODO: Enter answer here...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3:** Why is test accuracy not monotonically increasing? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A3:** (TODO: Enter answer here...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4:** You should also see jaggedness in the test curve toward the left. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A4:** (TODO: Enter answer here...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also generate similar curves by changing the maximum depth hyperparameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve = runClassifier.hyperparamCurveSet(dt.DT({}), 'maxDepth', [1,2,4,6,8,12,16], datasets.SentimentData)\n",
    "runClassifier.plotCurve('DT on Sentiment Data (hyperparameter)', curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the x-axis is the value of the maximum depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5:** You should see training accuracy monotonically increasing and\n",
    "test accuracy making something like a hill.  Which of these is\n",
    "*guaranteed* to happen a which is just something we might expect to\n",
    "happen?  Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A5:** (TODO: Enter answer here...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
